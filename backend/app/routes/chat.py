from fastapi import APIRouter, WebSocket, HTTPException, WebSocketDisconnect,File, UploadFile, Form
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import json
import uuid
from datetime import datetime
import asyncio
import os
from app.utils.llm_helper import llm_helper
from app.utils.conversation_manager_usesql import conversation_manager
from app.utils.memory_manager import MemoryManager
from app.agents.report_agent import  report_agent
from app.services.file_service import file_service
from app.services.index_service import index_service
from app.services import chunking_service
from app.services.db_service import DatabaseService
from app.database import SessionLocal
from sqlalchemy import text as sql_text
from app.services.index_service import index_service
from app.services import extraction_service, chunking_service
from app.config import CONV_TOPK, KB_TOPK

memory_manager = MemoryManager()
memory_manager.create_or_load()


router = APIRouter(prefix="/chat", tags=["chat"])

class ChatMessageRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None

class ChatMessageResponse(BaseModel):
    message_id: str
    content: str
    conversation_id: str
    role: str
    timestamp: str

class ConversationCreateRequest(BaseModel):
    title: Optional[str] = None

class ConversationItem(BaseModel):
    id: str
    title: str
    preview: str
    time: str
    message_count: int

class ConversationListResponse(BaseModel):
    conversations: List[ConversationItem]

class ReportGenerateRequest(BaseModel):
    conversation_id: str
    template_type: Optional[str] = "standard"
    custom_instructions: Optional[str] = None

class ReportOptimizeRequest(BaseModel):
    conversation_id: str
    current_report: str
    optimization_request: str

class ReportResponse(BaseModel):
    report_id: str
    content: str
    conversation_id: str
    timestamp: str
class FileUploadResponse(BaseModel):
    file_id: str
    file_name: str
    file_info: Dict
    analysis_data: Dict
    insights: str
    conversation_id: str

class FileItem(BaseModel):
    id: str
    conversation_id: str
    file_name: str
    file_path: str
    file_size: int
    file_format: str
    file_info: Optional[Dict] = None
    insights: Optional[str] = None
    created_at: str
    updated_at: str

class FileListResponse(BaseModel):
    files: List[FileItem]
@router.post("/upload", response_model=FileUploadResponse)
async def upload_file(
    file: UploadFile = File(...),
    conversation_id: str = Form(...)
):
    """ä¸Šä¼ å¹¶åˆ†ææ–‡ä»¶"""
    try:
        # éªŒè¯æ–‡ä»¶æ ¼å¼
        file_extension = os.path.splitext(file.filename)[1].lower()
        if file_extension not in file_service.supported_formats:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(file_service.supported_formats)}"
            )
        
        # å¤„ç†æ–‡ä»¶ä¸Šä¼ å’Œåˆ†æ
        result = await file_service.process_upload_and_analyze(file, conversation_id)
        
        if not result["success"]:
            raise HTTPException(status_code=500, detail=result["error"])
        
        # ç”±äºå½“å‰çš„ file_service æ²¡æœ‰ä¿å­˜åˆ°æ•°æ®åº“å¹¶è¿”å› IDï¼Œ
        # æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ä¿å­˜æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“
         # æ‰‹åŠ¨ä¿å­˜æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“
        try:
            db_service = DatabaseService(SessionLocal())
            file_record = db_service.create_file_record(
                conversation_id=conversation_id,
                file_name=file.filename,
                file_path=result["file_path"],
                file_size=result["file_info"]["file_size"],
                file_format=result["file_info"]["file_format"],
                file_info=result["file_info"],
                analysis_data=result["analysis_data"],
                insights=result["insights"]
            )
            # æ„å»ºå‘é‡ç´¢å¼•ï¼ˆä»¥æ–‡ä»¶IDä¸ºå‘½åç©ºé—´ï¼‰
            try:
                full_text = (result.get("content_data") or {}).get("full_text") or ""
                if not full_text:
                    # å…¼å®¹ï¼šä»ç»“æ„åŒ–å†…å®¹æ‹¼æ¥
                    cd = result.get("content_data") or {}
                    parts = []
                    for p in cd.get("pages", []) or []:
                        parts.append(p.get("content", ""))
                    for p in cd.get("paragraphs", []) or []:
                        parts.append(p.get("content", ""))
                    for s in cd.get("slides", []) or []:
                        parts.append(s.get("content", ""))
                    full_text = "\n".join(parts)
                if full_text:
                    file_service.build_vector_store(file_record["id"], full_text)
                    # åŒæ­¥å…¥åº“åˆ°ä¼šè¯ç©ºé—´ conv_<conversation_id>
                    try:
                        docs = chunking_service.chunk_from_text(full_text, kb=f"conv_{conversation_id}", file_name=file.filename)
                        index_service.upsert_docs(f"conv_{conversation_id}", docs)
                    except Exception:
                        pass
            except Exception:
                pass
        except Exception as db_error:
            print(f"æ•°æ®åº“ä¿å­˜é”™è¯¯: {str(db_error)}")
            # å¦‚æœæ•°æ®åº“ä¿å­˜å¤±è´¥ï¼Œä½¿ç”¨ä¸´æ—¶ID
            file_record = {
                "id": str(uuid.uuid4()),
                "conversation_id": conversation_id,
                "file_name": file.filename,
                "file_path": result["file_path"],
                "file_size": result["file_info"]["file_size"],
                "file_format": result["file_info"]["file_format"]
            }
        
        # æ·»åŠ æ–‡ä»¶åˆ†ææ¶ˆæ¯åˆ°å¯¹è¯
        analysis_message = {
            "id": str(uuid.uuid4()),
            "role": "assistant",
            "content": f"ğŸ“„ æ–‡ä»¶åˆ†æå®Œæˆï¼š\n\n{result['insights']}",
            "timestamp": datetime.now().isoformat(),
            "tool_call": {
                "name": "file_analyzer",
                "arguments": {
                    "file_name": file.filename,
                    "file_path": result["file_path"]
                },
                "status": "completed"
            }
        }
        conversation_manager.add_message(conversation_id, analysis_message)
        
        return FileUploadResponse(
            file_id=file_record["id"],
            file_name=file.filename,
            file_info=result["file_info"],
            analysis_data=result["analysis_data"],
            insights=result["insights"],
            conversation_id=conversation_id
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
@router.get("/files/{conversation_id}", response_model=FileListResponse)
async def list_files(conversation_id: str):
    """è·å–å¯¹è¯ä¸­çš„æ–‡ä»¶åˆ—è¡¨"""
    try:
        db_service = DatabaseService(SessionLocal())
        files = db_service.get_files_by_conversation(conversation_id)
         # è½¬æ¢ä¸º FileItem å¯¹è±¡
        file_items = []
        for file in files:
            file_items.append(FileItem(
                id=file["id"],
                conversation_id=file["conversation_id"],
                file_name=file["file_name"],
                file_path=file["file_path"],
                file_size=file["file_size"],
                file_format=file["file_format"],
                file_info=file["file_info"],
                insights=file["insights"],
                created_at=file["created_at"],
                updated_at=file["updated_at"]
            ))
        
        return FileListResponse(files=file_items)
       
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")

@router.get("/files/{file_id}/preview")
async def preview_file(file_id: str):
    """é¢„è§ˆæ–‡ä»¶"""
    try:
        preview_content = file_service.get_file_preview(file_id)
        return {"preview": preview_content, "file_id": file_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é¢„è§ˆæ–‡ä»¶å¤±è´¥: {str(e)}")
       
def _now():
    return datetime.utcnow().isoformat()

def _safe_llm_content(response):
    try:
        return response["choices"][0]["message"]["content"]
    except Exception:
        return ""

@router.post("/", response_model=ChatMessageResponse)
async def send_chat_message(request: ChatMessageRequest):
    """å‘é€èŠå¤©æ¶ˆæ¯"""
    try:
        # å¦‚æœæ²¡æœ‰å¯¹è¯IDï¼Œåˆ›å»ºæ–°å¯¹è¯
        conversation_id = request.conversation_id
        if not conversation_id:
            # æ ¹æ®ç¬¬ä¸€æ¡æ¶ˆæ¯ç”Ÿæˆå¯¹è¯æ ‡é¢˜
            title = request.message[:20] + "..." if len(request.message) > 20 else request.message
            conversation_id = conversation_manager.create_conversation(title)
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        user_message = {
            "id": str(uuid.uuid4()),
            "role": "user",
            "content": request.message,
            "timestamp": datetime.now().isoformat()
        }
        conversation_manager.add_message(conversation_id, user_message)

        # æ£€æŸ¥æ˜¯å¦æ˜¯æŠ¥å‘Šç”Ÿæˆè¯·æ±‚
        if "ç”ŸæˆæŠ¥å‘Š" in request.message or "å¸®æˆ‘å†™æŠ¥å‘Š" in request.message:
            # è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š
            report_content = await generate_report_automatically(conversation_id)
            
            # æ·»åŠ æŠ¥å‘Šä½œä¸º AI æ¶ˆæ¯
            ai_message = {
                "id": str(uuid.uuid4()),
                "role": "assistant",
                "content": f"å¥½çš„ï¼Œæˆ‘å·²ç»æ ¹æ®æˆ‘ä»¬çš„å¯¹è¯ç”Ÿæˆäº†æŠ¥å‘Šï¼š\n\n{report_content}",
                "timestamp": datetime.now().isoformat(),
                "tool_call": {
                    "name": "report_generator",
                    "arguments": {"type": "auto_generated"},
                    "status": "completed"
                }
            }
            conversation_manager.add_message(conversation_id, ai_message)
            
            return ChatMessageResponse(
                message_id=ai_message["id"],
                content=ai_message["content"],
                conversation_id=conversation_id,
                role="assistant",
                timestamp=ai_message["timestamp"]
            )
        
        # è·å–å¯¹è¯å†å²
        messages = conversation_manager.get_messages(conversation_id)
        formatted_messages = [{"role": msg["role"], "content": msg["content"]} for msg in messages]
        
        # è°ƒç”¨ DeepSeek API
        response = await llm_helper.chat_completion(
            messages=formatted_messages,
            temperature=0.7
        )
        
        # æå– AI å›å¤
        ai_content = response["choices"][0]["message"]["content"]
        
        # æ·»åŠ  AI æ¶ˆæ¯
        ai_message = {
            "id": str(uuid.uuid4()),
            "role": "assistant",
            "content": ai_content,
            "timestamp": datetime.now().isoformat()
        }
        conversation_manager.add_message(conversation_id, ai_message)
        
        return ChatMessageResponse(
            message_id=ai_message["id"],
            content=ai_content,
            conversation_id=conversation_id,
            role="assistant",
            timestamp=ai_message["timestamp"]
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å‘é€æ¶ˆæ¯å¤±è´¥: {str(e)}")

async def _safe_send(websocket: WebSocket, message: dict, chunk_size: int = 2000):
    """å®‰å…¨å‘é€ï¼Œé¿å…å•æ¡æ¶ˆæ¯è¿‡å¤§"""
    text = json.dumps(message, ensure_ascii=False)
    for i in range(0, len(text), chunk_size):
        await websocket.send_text(text[i:i + chunk_size])
        
@router.websocket("/ws")
async def websocket_chat(websocket: WebSocket):
    """WebSocket å®æ—¶èŠå¤©ï¼ˆä¿æŒæµå¼å“åº” + å¿ƒè·³ + finally closeï¼‰"""
    await websocket.accept()
    try:
        while True:
            # ä¸¤ä¸ªä»»åŠ¡ï¼šæ¥æ”¶æ¶ˆæ¯ / å¿ƒè·³
            data_task = asyncio.create_task(websocket.receive_text())
            heartbeat_task = asyncio.create_task(asyncio.sleep(30))  # 30 ç§’å¿ƒè·³

            done, pending = await asyncio.wait(
                {data_task, heartbeat_task},
                return_when=asyncio.FIRST_COMPLETED,
            )

            if data_task in done:
                # æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯
                data = data_task.result()
                message_data = json.loads(data)

                if message_data.get("type") == "user_message":
                    message = message_data.get("content", "")
                    conversation_id = (
                        message_data.get("conversation_id")
                        or conversation_manager.create_conversation()
                    )
                    kb_name = message_data.get("kb")

                    #1  ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°çŸ­æœŸå’Œé•¿æœŸè®°å¿†
                    user_message = {
                        "id": str(uuid.uuid4()),
                        "role": "user",
                        "content": message,
                        "timestamp": _now(),
                    }
                    conversation_manager.add_message(conversation_id, user_message)
                    
                    memory_manager.add_texts([user_message["content"]])

                    # 2. æ£€ç´¢é•¿æœŸè®°å¿†
                    long_term_results = memory_manager.search(message, k=3)
                    long_term_context = "\n".join([doc.page_content for doc in long_term_results])
                    # 3. å–çŸ­æœŸè®°å¿†
                    N = 10
                    short_term_messages = conversation_manager.get_messages(conversation_id)[-N:]
                    short_term_context = [{"role": msg["role"], "content": msg["content"]} for msg in short_term_messages]

                                        # 4. æ‹¼æ¥ä¸Šä¸‹æ–‡
                    if long_term_context:
                        system_prompt = f"ã€é•¿æœŸè®°å¿†ç›¸å…³å†…å®¹ã€‘\n{long_term_context}\nã€å½“å‰å¯¹è¯ã€‘"
                        formatted_messages = [{"role": "system", "content": system_prompt}] + short_term_context
                    else:
                        formatted_messages = short_term_context

                    # ç»„åˆæ£€ç´¢ï¼šä¼šè¯ç©ºé—´ + å¯é€‰ KB ç©ºé—´
                    try:
                        conv_docs = []
                        try:
                            conv_retriever = index_service.retriever(f"conv_{conversation_id}", k=CONV_TOPK)
                            conv_docs = conv_retriever.get_relevant_documents(message)
                        except Exception:
                            conv_docs = []
                        kb_docs = []
                        if kb_name:
                            try:
                                kb_retriever = index_service.retriever(kb_name, k=KB_TOPK)
                                kb_docs = kb_retriever.get_relevant_documents(message)
                            except Exception:
                                kb_docs = []
                        kn_segments = []
                        for d in conv_docs + kb_docs:
                            if d and getattr(d, 'page_content', None):
                                kn_segments.append(d.page_content)
                        if kn_segments:
                            knowledge_context = "\n".join(kn_segments[:5])
                            kc_prompt = f"ã€æ£€ç´¢çŸ¥è¯†ã€‘\n{knowledge_context}"
                            formatted_messages = [{"role": "system", "content": kc_prompt}] + formatted_messages
                    except Exception:
                        pass
                    # messages = conversation_manager.get_messages(conversation_id)
                    # formatted_messages = [
                    #     {"role": msg["role"], "content": msg["content"]}
                    #     for msg in messages
                    # ]

                    # é€šçŸ¥å‰ç«¯å¼€å§‹æµ
                    await websocket.send_text(json.dumps({
                        "type": "stream_start",
                        "message": "å¼€å§‹ç”Ÿæˆå›å¤..."
                    }))

                    full_response = ""

                    try:
                        # âš¡ æµå¼è¿”å›
                        async for chunk in llm_helper.chat_completion_stream(
                            messages=formatted_messages,
                            temperature=0.7,
                        ):
                            if chunk.get("type") == "stream_chunk":
                                content = chunk.get("content", "")
                                if content:
                                    full_response += content
                                    await websocket.send_text(json.dumps({
                                        "type": "stream_chunk",
                                        "content": content
                                    }))

                            elif chunk.get("type") == "error":
                                await websocket.send_text(json.dumps(chunk))
                                break

                    except Exception as e:
                        await websocket.send_text(json.dumps({
                            "type": "error",
                            "content": f"LLMæµå¼å“åº”å¼‚å¸¸: {str(e)}"
                        }))

                    # ä¿å­˜ AI æ¶ˆæ¯
                    ai_message = {
                        "id": str(uuid.uuid4()),
                        "role": "assistant",
                        "content": full_response,
                        "timestamp": _now(),
                    }
                    conversation_manager.add_message(conversation_id, ai_message)

                    # é€šçŸ¥å‰ç«¯æµç»“æŸ
                    await websocket.send_text(json.dumps({
                        "type": "stream_end",
                        "content": full_response,
                        "conversation_id": conversation_id
                    }))

            elif heartbeat_task in done:
                # å®šæ—¶å¿ƒè·³
                await websocket.send_text(json.dumps({"type": "ping"}))

            # å–æ¶ˆæ²¡ç”¨çš„ä»»åŠ¡ï¼Œé˜²æ­¢å†…å­˜æ³„éœ²
            for task in pending:
                task.cancel()

    except WebSocketDisconnect:
        print("å®¢æˆ·ç«¯æ–­å¼€ WebSocket")
    except Exception as e:
        print("WebSocket é”™è¯¯:", e)
        try:
            await websocket.send_text(json.dumps({
                "type": "error",
                "content": f"WebSocket è¿æ¥é”™è¯¯: {str(e)}"
            }))
        except Exception:
            pass
    finally:
        # âš ï¸ ç¡®ä¿å…³é—­
        try:
            await websocket.close()
        except Exception:
            pass

@router.post("/conversations", response_model=dict)
async def create_conversation(request: ConversationCreateRequest):
    """åˆ›å»ºæ–°å¯¹è¯"""
    conversation_id = conversation_manager.create_conversation(request.title)
    conversation = conversation_manager.get_conversation(conversation_id)
    
    return {
        "id": conversation["id"],
        "title": conversation["title"],
        "created_at": conversation["created_at"]
    }

@router.get("/conversations", response_model=ConversationListResponse)
async def list_conversations():
    """è·å–å¯¹è¯åˆ—è¡¨"""
    conversations = conversation_manager.get_all_conversations()
    
    # æŒ‰æ›´æ–°æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
    conversations.sort(key=lambda x: x["updated_at"], reverse=True)
    
    conversation_items = []
    for conv in conversations:
        # ç”Ÿæˆé¢„è§ˆ
        preview = conversation_manager.get_conversation_preview(conv["id"])
        
        # æ ¼å¼åŒ–æ—¶é—´
        updated_time = datetime.fromisoformat(conv["updated_at"].replace('Z', '+00:00'))
        time_str = updated_time.strftime("%m-%d %H:%M")
        
        conversation_items.append(ConversationItem(
            id=conv["id"],
            title=conv["title"],
            preview=preview,
            time=time_str,
            message_count= len(conv.get("messages", []))
        ))
    
    return ConversationListResponse(conversations=conversation_items)

@router.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: str):
    """è·å–å¯¹è¯è¯¦æƒ…"""
    conversation = conversation_manager.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(status_code=404, detail="å¯¹è¯ä¸å­˜åœ¨")
    
    return conversation

@router.delete("/conversations/{conversation_id}")
async def delete_conversation(conversation_id: str):
    """åˆ é™¤å¯¹è¯"""
    success = conversation_manager.delete_conversation(conversation_id)
    if not success:
        raise HTTPException(status_code=404, detail="å¯¹è¯ä¸å­˜åœ¨")
    
    return {"message": "å¯¹è¯å·²åˆ é™¤"}

@router.post("/conversations/{conversation_id}/clear")
async def clear_conversation(conversation_id: str):
    """æ¸…ç©ºå¯¹è¯æ¶ˆæ¯"""
    conversation = conversation_manager.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(status_code=404, detail="å¯¹è¯ä¸å­˜åœ¨")
    
    conversation["messages"] = []
    conversation["updated_at"] = datetime.now().isoformat()
    return {"success": True}

@router.get("/conversations/{conversation_id}/retrieval/status")
async def conv_retrieval_status(conversation_id: str):
    """è·å–ä¼šè¯æ£€ç´¢ç©ºé—´çŠ¶æ€ï¼ˆchunk æ•°ï¼‰"""
    try:
        chunks = index_service.total_chunks(f"conv_{conversation_id}")
        return {"conversation_id": conversation_id, "doc_chunks": chunks}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ä¼šè¯æ£€ç´¢çŠ¶æ€å¤±è´¥: {str(e)}")

@router.post("/conversations/{conversation_id}/retrieval/rebuild")
async def conv_retrieval_rebuild(conversation_id: str):
    """é‡å»ºä¼šè¯æ£€ç´¢ç©ºé—´ï¼ˆæ ¹æ® file_records é‡æ–°æŠ½å–å¹¶å…¥åº“ï¼‰"""
    try:
        # æ¸…ç©ºå‘é‡åº“ç›®å½•
        index_service.rebuild(f"conv_{conversation_id}")
        # è¯»å– file_records
        db = SessionLocal()
        rows = db.execute(sql_text(
            "SELECT id, file_name, file_path FROM file_records WHERE conversation_id = :cid AND is_active = 1"
        ), {"cid": conversation_id}).fetchall()
        total_files = 0
        total_chunks = 0
        for r in rows:
            file_name = r[1]
            file_path = r[2]
            try:
                extracted = extraction_service.extract(file_path)
                text = chunking_service.text_from_extracted(extracted)
                docs = chunking_service.chunk_from_text(text, f"conv_{conversation_id}", file_name)
                index_service.upsert_docs(f"conv_{conversation_id}", docs)
                total_files += 1
                total_chunks += len(docs)
            except Exception:
                continue
        return {"success": True, "conversation_id": conversation_id, "files": total_files, "chunks": total_chunks}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é‡å»ºå¤±è´¥: {str(e)}")

@router.post("/reports/generate", response_model=ReportResponse)
async def generate_report(request: ReportGenerateRequest):
    """ç”ŸæˆæŠ¥å‘Š"""
    try:
        # ä»å¯¹è¯ä¸­æå–ä¿¡æ¯
        report_info = conversation_manager.extract_report_info(request.conversation_id)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = await report_agent.generate_report(
            report_info, 
            request.template_type or "standard"
        )
        
        # æ·»åŠ æŠ¥å‘Šç”Ÿæˆæ¶ˆæ¯åˆ°å¯¹è¯
        report_message = {
            "id": str(uuid.uuid4()),
            "role": "assistant",
            "content": f"æŠ¥å‘Šå·²ç”Ÿæˆï¼š\n\n{report_content}",
            "timestamp": datetime.now().isoformat(),
            "tool_call": {
                "name": "report_generator",
                "arguments": {
                    "type": "manual",
                    "template": request.template_type
                },
                "status": "completed"
            }
        }
        conversation_manager.add_message(request.conversation_id, report_message)
        
        return ReportResponse(
            report_id=str(uuid.uuid4()),
            content=report_content,
            conversation_id=request.conversation_id,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")

@router.post("/reports/optimize", response_model=ReportResponse)
async def optimize_report(request: ReportOptimizeRequest):
    """ä¼˜åŒ–æŠ¥å‘Š"""
    try:
        # ä¼˜åŒ–æŠ¥å‘Š
        optimized_report = await  report_agent.optimize_report(
            request.current_report,
            request.optimization_request
        )
        
        # æ·»åŠ ä¼˜åŒ–åçš„æŠ¥å‘Šåˆ°å¯¹è¯
        report_message = {
            "id": str(uuid.uuid4()),
            "role": "assistant",
            "content": f"æŠ¥å‘Šå·²ä¼˜åŒ–ï¼š\n\n{optimized_report}",
            "timestamp": datetime.now().isoformat(),
            "tool_call": {
                "name": "report_optimizer",
                "arguments": {
                    "request": request.optimization_request
                },
                "status": "completed"
            }
        }
        conversation_manager.add_message(request.conversation_id, report_message)
        
        return ReportResponse(
            report_id=str(uuid.uuid4()),
            content=optimized_report,
            conversation_id=request.conversation_id,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŠ¥å‘Šä¼˜åŒ–å¤±è´¥: {str(e)}")
async def generate_report_automatically(conversation_id: str) -> str:
    """è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š"""
    try:
        # ä»å¯¹è¯ä¸­æå–ä¿¡æ¯
        report_info = conversation_manager.extract_report_info(conversation_id)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = await  report_agent.generate_report(report_info, "standard")
        return report_content
    except Exception as e:
        return f"è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}"
